#+TITLE: Wicst Data Organization
#+TODO: TODO(t) REVISIT(r) REVIEW(v) | DONE(d) IGNORED(i)

* Project Design
The project can be split up into a three-tier architecture of Presentation/Logical/Physical. This is similar to business intelligence "[[https://docs.oracle.com/en/middleware/bi/analytics-server/datamodel-oas/semantic-models-architecture.html][semantic architecture]]" or web design's three-tier architecture. I like to think of it in analogy to statistical contexts as: Raw Data -> Modeling -> Results

1. Presentation
   - This tier is customized for the end user and has the highest level of abstraction over the raw data. This should be easy to use for non-technical users, and should not require specialized knowledge of the data curation or sources of the data. There are often many services that this presentation tier will have, each built for specific purposes
2. Logical
   - This tier should contain all the "business logic" of what this project offers. In this case, I would presume this mostly contains a series of statistical models that summarize the data. If data visualizations and data reports are desired in the presentation tier, then this tier will contain all the code that goes behind generating those reports. Ideally, the structure of this tier matches the design of the presentation tier, and is relatively robust to changes that happen in the Physical and Presentation tier. Many times this will result in a series of "endpoints" in which the presentation tier can consume data in a consistent format.
3. Physical
   - This tier is how the data is actually stored and organized. The design of these databases and implementation of this data should be highly dependent on internal operations, and should be regularly curated so that the data is clean and organized. We will aim for a balance of consistency, availability, and robustness.
** Customers (Presentation Layer)
*** Questions for each Customer
**** What is the reason for them to use this data?
- "We need to see summaries of this data for grant writing"
- "We would like to see recommendations for seeds in the upcoming planting season"
**** Are there any data privacy concerns that should be addressed?
- Do we need to set any limits on how much/how often they will be accessing this data?
- Are there any legal restrictions that need to be met?
**** Who and how will they be accessing the Data?
- Access through the browser? through their phone?
- Will they need direct access to the data? Or be able to submit requests for updating the data?
- User authentication or verification?
**** How critical is this Customer?
**** How should they be able to access the data?
- Are they using this data in production, and building tools on top of this? Will they need an API to access our data?
- Do they want to be able to download csv files of their summary?
- What visualizations or reports might they want, and how frequently?
** Statistical Analysis (Logical Layer)
*** How should the implementation of analyses be done? R? Python?
*** What summaries would be the most useful?
*** Do we need to create logic for customers to update our data? or just read?
** The Data (Physical Layer)
*** What is the structure of the current data?
*** What is necessary to keep and clean?
*** How often will the data need to be updated and read from?
*** Where should this be hosted?

* Execution Plan
Time will be split evenly across the three layers of the project design: Presentation(33%), Logical(33%), Physical(33%). The time spent on the presentation layer and physical layer I anticipate will need most of your time, as those are very "practice dependent".

I'll propose that my work will have roughly 3 phases, and progress in mostly a top-down manner.

1. Minimum Viable (~10%)
   - We will identify /one/ customer, and create all three layers of the project to service the one customer. There will be strict boundaries on the data integrated into the minimum product
   - The customer identified will be representative of general pattern of needs in the project, and feedback sessions will iterate on the basic product until it is serviceable and can be utilized live.
2. Design for current customers (~60%)
   - Taking into consideration the aggregate needs of the customers /currently/ serviced, we will create a design that adheres best to the current utilization of data. Database schemas have appropriate identifying information, security practices are implemented, etc.f
     - Flowcharts? Page 12 [[https://cms.library.wisc.edu/archives/wp-content/uploads/sites/21/2015/06/2014-Electronic-Business-Communication-and-University-Records.pdf][2014 Business Communication and University Records]]
   - Customer needed data will be curated and cleaned, organized into well-defined schemas with identifying information
   - Data Retention Schedules will be developed, with policies on when and how data will be curated.
     - [[https://www.library.wisc.edu/archives/records-management/uw-madison-records-retention-schedules-and-disposition/][retention schedules at UW]]
   - Data stewards and responsibilities will be identified and assigned.
3. Design for scalability/persistence (~30%)
   - I will try to make this system healthy enough to run on its own after I'm no longer on this project.
   - This will be writing appropriate documentation, and passing on the necessary skills to keep these services in operation.
   - Hosting services will also be a considderation. I will prioritize looking for a department, campus, commerical solution in order keep these services available.
     - department will also have web hosting solutions available if needed
     - RPosit has some platforms for computing machine time.
     - DOIT has solutions for Oracle,MSSQL, and dedicated staff to keeping these services running.
     - There are associated costs with keeping these databases up as well, and I would also rely on their expertises in this regard. If we choose one of these routes, I'll be responsible for communicating our project's technical needs. I will try to come up with reasonable cost estimates for the upkeep of this project.
     - [[https://storage.researchdata.wisc.edu/][Research Data Services]] also has some campus related tools we may be able to use, including cloud services like Amazon web services, and Azure.
     - At this time, I'm considering single file endpoints, with Rposit for computing, UW for web hosting. Sqlite can be created for single file endpoint.
   - Can also develop and track project metrics to make it easier to justify for future funding projects.
* Task List
** Data
** Knowledge
* Background Information
** Farming
*** Fertilizers
- three numbers for starting fertilizers 9-11-30 means Nitrogen-Phosphorus-Potassium
- Liming is mostly for controlling ph of the soil, measured by eutralizing Index. It's the carbonate CO3-2
  - 80-89 grade is the neutralizing index zones, so the higher the index zone, the higher the quality of lime. It's finer or has more carbonate.
** Terminology
- bu/a :: bushel per acre
- T/a :: tons per acre
- PPNT :: Preplant soil nitrate test
  + measures residual/carryover N
- PSNT ::
- leaching ::
- os :: oat straw
- of :: oat forage (oatlage)
- wg :: wheat grain
- ws :: wheat straw
- hay tedding :: lifting and separating hay to speed up dry down time. "fluffing"
- windrow :: row of cut hay/small grain crop. Normally before being baled combined or rolled
- raking :: seems another method of making windrows,
- hay :: cut grass left out to dry, generally used for food.
  - 10% moisture
- straw :: wheat/oats/barley after the combine that cuts off the berry stuff on the top.
  - generally used for bedding, decoration, scattered etc.
- hay bale  :: a bundle that has more moisture than straw bale
- straw bale :: oat/wheat straw after the cutting, super dry
- baleage :: fermented forage >  "baled" > wrapped in a tube or plastic
  - 45-55% moisture
  - basically skip the
- haylage :: forage chopper > bagged/silo/bunk/covered
  - 60-70% moisture ("high moisture haylage")
  - called such because it's left to wilt for shorter period of time than normal hay
- forage ::
- silage :: anything stored in silo
- ensile :: put into a silo to preserve as silage
- plowing :: technically a type x of tilling but more intense
- moldboard plowing :: more scoop and flip action of plowing
- chisel plowing :: more claw deep and disturb type of plowing
- flail mower :: cutter adapted for occasional immovable objects, will just "not cut" the rock instead of catching it and throwing it.
  - also can cut lower to the ground.
- cultivator :: it's like mixing top soil... technically tilling. but "no-till system"
- tine weeding :: little claw like thing dragging behind
- ANPP :: aerial net primary production
  - seems like measuring the surface area and productivity of the cover.
  - they have canapeo measurements
- paddock :: enclosed area for pasturing or exercise animals
** Data
- each season has multiple crops, wheat (grain, straw) and alfalfa (multiple cuts)
- two sites ARL and LAC. No LAC past 2003
- system 1:6, 14:15.
  - 14 only shows up in 2002, and 15 only shows up in 1999-2002. These look like modifications of 4 and 5. From notes tab:
    #+begin_quote
    all plots for cuts 3 and 4 of CS4 and CS5 were not sampled for quality analysis (not sure why)
    #+end_quote
- blocks 16 each year starting in 2017, 14 each year from 1989 - 2016.
- system 2 has only filler corn the first year
- system 3: 1989, 1990 don't have all 3 crop1. 2019 is missing wg?
  - 1994, LAC, there's one wg rotation
- oat grain crop1
** Actionable
*** 1989 system 2 has potential mislabel
- supposed to be corn/sb but two rows of block 1 have both labeled as corn and none with soybean.
  #+begin_src R
wicst_raw |>
  filter(system == 2) |>
  select(year, crop1, crop2, crop3) |>
  distinct(year, crop1, crop2, crop3) |>
  xtabs(~year + crop1, data =  _)
  #+end_src
- it's possible this is just how the trial started? It's unclear how this
** Treatment
- "c silage" is 2017-2019
- "c_silage" is 2020-2023
* Table Documentation/Notes
** sites
- description: holds information relevant to where research plots are
** plots
- system should be a property of plots... but the lakeland plots are an excepttion to that requirement what to do here...
** harvestings
- "Collecting a product off the field, no matter the form"
** Plantings
** Fertilizings
** Persons
** HarvestPlantings
- linkage table
- resolves many to many relationship between Harvests and Plantings because multiple crops can be involved in a harvest (oats/alfalfa). Multiple harvests can be made of a single crop (alfalfa).
- plantings may not be harvested, instead they may be tilled into the land, or they may simply die. but the reverse harvest must have
** HarvestPersons?
- maybe not necessary
** HarvestLosses
- captures any losses recorded in the field during harvest times, needs to be separate because sometimes the "true" yield reflective shouldn't adjust for these losses. losses happen in the real world too.
** HarvestingDetails?
This table preserves some of the intermediary tools used to calculate final harvest numbers. Generally there are additional implements used, such as bags for straw and wagons for bales. We require that these numbers be associated with specific harvests. If we harvest 3 cuts of alfalfa through the season, it's possible each cut will use a different bag.
TBD: do we really need wet -> dry -> bag?
- harvesting_id (PK, FK)
- wet_bag_weight
- dry_bag_weight?
  - I believe some datatables also measure the dry bag... is this because the bag itself has some moisture?
- wagon_color
- wagon_weight
- bag_and_wet_product
- bag_and_dry_product
- notes?
  - since this is 1-1 with the harvest, this will also be anything related to the harvest itself
** HarvestingDimensions
Each harvest must capture an /intended/ area. These dimensions are not always given, but given that the harvest area for some plots will vary depending on the measurements taken each year, it's important that these intermediary numbers also be preserved as those measurements will affect yield/area calculations. Finally, there is some noted confusion about what "numbers" to use for length/width in the datasheets, so it would be nice to see if there are errors being made about particular years. The numbers are associated with single harvests. should be a 1-1 optional participation?
TBD: maybe merged with details table
- harvesting_id (PK, FK)
- plot
- harvest_length
- harvest_width
** biomassings
it looks like 1 evaluation per season for everything except pasture. In the datasheets,even at a single date, there are multiple "bags", if we record the bag weight for those instances, each row in the table is a bagging. I'd say it should be a cut evaluation or something. plot -> cut ->
- the length of plot changes for each plot cutting... so if pasture and anpp go into the same table, each cut by definition can't be the same quadrant because they will have different areas. we should consider plot(cut x quadrat)
*** Questions
- Does the cutting in a field season happen in the exact same quadrant?
- Do the cuts on N, C, S happen at the same time? can we assume that they might be different
*** Fields
- plot
- section
- date
- cut/quadrat
- quadrat size
- crop
  - alfalfa
  - weeds
  - oats
  - berseem clover
  - red clover
  - residue
  - pasture
* Relationships
- sites-plots
- plots is an identifying relationship
**  HarvestLosses 3o---| Harvestings
- Losses refers to harvestings
- one to many because many losses in a field at harvest time, different sections of plot
- Non-identifying because
  - the distinction is actually not THAT important, since we're using a surrogate key (not a composite) for harvest losses, ie, it's going to be redundant to make the harvest id also a key, because our surrogate key harvestlosses_id will identify the loss.
- harvestloss -> harvestings participation is MANDATORY because you can't have a loss without a harvest
- the other way harvestings -> loss is OPTIONAL because not all harvestings will have a loss.
  - on the joins... you'll just have to rememeber to hit this table, and zero out the harvests without any values here.
** HarvestingDetails |o---| Harvestings
- details refer to harvestings
- 1-1 because... only one action being described
  #+begin_quote
CREATE SCHEMA IF NOT EXISTS `myagg` DEFAULT CHARACTER SET utf8
CREATE TABLE IF NOT EXISTS `myagg`.`EIHarvests?` (
)
ENGINE = InnoDB
  #+end_quote
* Business Rules
* Style Guide
** Table Names
- lowercase and all plural
- SAS needs all the tablenames to be lowercase otherwise they won't get imported
* GCP
- postg
** postgres db
- pass: Sanfordlab
- myliou:iamtheadmin
** Journey
- download gcloud cli through the sdk, enable IAM,
** Getting into the db
1. Direct connection
   The database will have a public facing IP address. If you try to connect to that directly ip, port 5432, then you'll be asked username/password and you're in! Since this is weaker in security, google will require that you specify which ip addresses you'll be connecting from, so that people can't just bruteforce attack your database. You need to specify a mask of ip addresses as a range.
2. SQL Proxy Auth
   Essentially you're setting up a tunnel from your computer to
** SQL Proxy Auth
A "proxy" is just another networking way of connecting to your database.
- setup a dedicated host
* Notes
** [2024-10-09 Wed] wisconet with david
- attendance: izzy, david, chris, david
- 4 instances of ec2, relational dbs, mysql.
- each station has a folder for achives
- normalzied everything for consistent measures, basically every column, boto3
** [2024-10-03 Thu]
- Adam: 146.151.194.52
- Gregg: 146.151.200.14
** [2024-09-26 Thu] wheat yield, harvest/plant review, visit to farm
- [ ] bag weight, length, width to harvest table
- [ ] row spacing, planting depth to planting table
- ANPP? really should be a separate table as its another condsequence
- explanation of the wheat yields. The grain is cut off, then the straw is bagged as "wet", then set in a room to be dried
** <2024-09-06 Fri> Organic Marketing World, how
** [2024-09-16 Mon] First Meeting with Adam
*** "I want all of the soil test phosphorus data from your organic corn systems from 1990 to 2010"
